{
    "meta-llama/llama-3.1-8b-instruct": 4.700000000000001,
    "meta-llama/llama-3.1-70b-instruct": 14.1,
    "meta-llama/llama-3.1-405b-instruct": 16.9,
    "mistralai/mistral-nemo": 5.499999999999999,
    "mistralai/mistral-large": 14,
    "mistralai/mixtral-8x22b-instruct": 11.700000000000001,
    "openai/gpt-4o-mini": 15.500000000000002,
    "openai/gpt-4o": 20.799999999999997,
    "openai/gpt-4-turbo": 20.1,
    "openai/gpt-4": 15.999999999999996,
    "anthropic/claude-3-haiku": 5.6000000000000005,
    "anthropic/claude-3-opus": 16.4,
    "anthropic/claude-3.5-sonnet": 20.1,
    "qwen/qwen-2-7b-instruct": 5.799999999999999,
    "qwen/qwen-2-72b-instruct": 13.399999999999999,
    "microsoft/phi-3-mini-128k-instruct": 5.1,
    "microsoft/phi-3-medium-4k-instruct": 9.1,
    "google/gemma-2-27b-it": 7.8,
    "google/gemma-2-9b-it": 5.9,
    "google/gemini-flash-1.5": 10.6,
    "google/gemini-pro-1.5": 16.900000000000002,
    "nousresearch/hermes-2-pro-llama-3-8b": 3.3000000000000007,
    "nousresearch/hermes-2-theta-llama-3-8b": 1.8000000000000003,
    "microsoft/wizardlm-2-7b": 3.1000000000000005,
    "microsoft/wizardlm-2-8x22b": 12.8,
    "deepseek/deepseek-chat": 14.700000000000001,
    "deepseek/deepseek-coder": 12.4,
    "cognitivecomputations/dolphin-llama-3-70b": 2.5999999999999996,
    "cognitivecomputations/dolphin-mixtral-8x22b": 9.999999999999998,
    "alpindale/magnum-72b": 12
}